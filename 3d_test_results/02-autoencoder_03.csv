,batchsize,timesteps,optimizer,loss,metrics,layer1,preprocess,avg_epochs,avg_loss,avg_valid_loss,avg_test_loss_0,avg_test_loss_1
0,40,16,adam,mse,mse,{'filters': 1},Stable Filter,16.666666666666668,0.003718311432749033,0.004766471528758605,0.006042636310060819,0.005418526319166024
1,40,16,adam,mse,mse,{'filters': 2},Stable Filter,16.333333333333332,0.002355145445714394,0.00316573865711689,0.004547338932752609,0.0039800664720435934
2,40,16,adam,mse,mse,{'filters': 3},Stable Filter,14.333333333333334,0.001706342794932425,0.0024378154582033553,0.0028602213909228644,0.0026034164863328138
3,40,16,adam,mse,mse,{'filters': 4},Stable Filter,14.666666666666666,0.0012091643487413724,0.0018021402647718787,0.0025360831835617623,0.002225203439593315
4,40,16,adam,mse,mse,{'filters': 5},Stable Filter,15.666666666666666,0.0008984443653995792,0.0013992729363963008,0.0019345352581391733,0.0014441822422668338

from keras import Input, layers, Model

TIMESTEPS = 16
VECTOR_SIZE = 10

class Encoder_Decoder:
    def __init__(self, number_of_features):
        inputs = Input(shape=(TIMESTEPS, number_of_features))
        x = layers.Conv1D(1, 3, padding="same")(inputs)
        outputs = layers.Conv1DTranspose(number_of_features, 3, padding="same")(x)
        self.model = Model(inputs=inputs, outputs=outputs)

    def target_function(self, data):
        x, y = data
        return x

OPTIONS = {
    "batchsize": [40],
    "timesteps": [TIMESTEPS],
    "optimizer": ["adam"],
    "loss": ['mse'],
    "metrics": ['mse'],
    "layer1": [{"filters": i} for i in range(1, 6)],
}