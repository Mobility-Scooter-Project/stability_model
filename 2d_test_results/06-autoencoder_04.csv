,batchsize,timesteps,optimizer,loss,metrics,layer1,preprocess,avg_epochs,avg_loss,avg_valid_loss,avg_test_loss_0,avg_test_loss_1
0,40,32,adam,mse,mse,{'units': 1},No Change,34.666666666666664,0.005243419048686822,0.005833733516434829,0.018685766806205113,0.010931800119578838
1,40,32,adam,mse,mse,{'units': 2},No Change,34.333333333333336,0.0038366742276897035,0.0045845334728558855,0.005969933855036895,0.003369175052891175
2,40,32,adam,mse,mse,{'units': 3},No Change,40.0,0.0028181530069559813,0.0031553296527514854,0.004610766967137654,0.0027651647881915173
3,40,32,adam,mse,mse,{'units': 4},No Change,37.666666666666664,0.00206433841958642,0.002457208000123501,0.0033011567623664937,0.0019293234217911959
4,40,32,adam,mse,mse,{'units': 5},No Change,38.0,0.0014046856279795368,0.0017500044001887243,0.00239321185896794,0.0012804986909031868

from keras import Input, layers, Model

TIMESTEPS = 32
VECTOR_SIZE = 10

class Encoder_Decoder:
    def __init__(self, number_of_features):
        inputs = Input(shape=(TIMESTEPS, number_of_features))
        lstm = layers.LSTM(VECTOR_SIZE, return_sequences=True)(inputs)
        outputs = layers.Conv1DTranspose(number_of_features, 3, padding="same")(lstm)
        self.model = Model(inputs=inputs, outputs=outputs)

    def target_function(self, data):
        x, y = data
        return x

OPTIONS = {
    "batchsize": [40],
    "timesteps": [TIMESTEPS],
    "optimizer": ["adam"],
    "loss": ['mse'],
    "metrics": ['mse'],
    "layer1": [{"units": i} for i in range(1, 6)],
}