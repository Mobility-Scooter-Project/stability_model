,batchsize,timesteps,optimizer,loss,metrics,layer1,preprocess,avg_epochs,avg_loss,avg_valid_loss,avg_test_loss_0,avg_test_loss_1
0,40,16,adam,mse,mse,{'filters': 1},No Change,17.666666666666668,0.005198747385293245,0.005706090480089188,0.018013831228017807,0.010448548632363478
1,40,16,adam,mse,mse,{'filters': 2},No Change,18.666666666666668,0.003714995225891471,0.004440980187306802,0.005329769880821307,0.0032097334818293652
2,40,16,adam,mse,mse,{'filters': 3},No Change,26.333333333333332,0.00274197602023681,0.0029989665684600673,0.004015652928501368,0.0024436872142056623
3,40,16,adam,mse,mse,{'filters': 4},No Change,23.333333333333332,0.0020396968660255275,0.00231944490224123,0.0031284946016967297,0.0018353166912371914
4,40,16,adam,mse,mse,{'filters': 5},No Change,30.666666666666668,0.0013640938559547067,0.0017072563835730155,0.0023350807993362346,0.0013254675626133878

from keras import Input, layers, Model

TIMESTEPS = 16
VECTOR_SIZE = 10

class Encoder_Decoder:
    def __init__(self, number_of_features):
        inputs = Input(shape=(TIMESTEPS, number_of_features))
        x = layers.Conv1D(1, 3, padding="same")(inputs)
        outputs = layers.Conv1DTranspose(number_of_features, 3, padding="same")(x)
        self.model = Model(inputs=inputs, outputs=outputs)

    def target_function(self, data):
        x, y = data
        return x

OPTIONS = {
    "batchsize": [40],
    "timesteps": [TIMESTEPS],
    "optimizer": ["adam"],
    "loss": ['mse'],
    "metrics": ['mse'],
    "layer1": [{"filters": i} for i in range(1, 6)],
}