,batchsize,timesteps,optimizer,loss,metrics,preprocess,avg_epochs,avg_loss,avg_valid_loss,avg_test_loss_0,avg_test_loss_1
0,40,16,adam,mae,mae,No Change,16.333333333333332,0.05072829748193423,0.05109137296676636,0.10107486695051193,0.08052857468525569
1,40,16,adam,mae,mse,No Change,15.666666666666666,0.05089583868781725,0.05081998184323311,0.09963116546471913,0.07897275437911351
2,40,16,adam,mse,mae,No Change,18.333333333333332,0.005221205453077952,0.0056986889491478605,0.017675510918100674,0.010179736651480198
3,40,16,adam,mse,mse,No Change,16.666666666666668,0.005239740169296662,0.005769447578738133,0.017873069892326992,0.010315870555738607

from keras import Input, layers, Model

TIMESTEPS = 16
VECTOR_SIZE = 10

class Encoder_Decoder:
    def __init__(self, number_of_features):

        inputs = Input(shape=(TIMESTEPS, number_of_features))
        x = layers.Conv1D(1, 3, padding="same")(inputs)
        outputs = layers.Conv1DTranspose(number_of_features, 3, padding="same")(x)
        self.model = Model(inputs=inputs, outputs=outputs)

    def target_function(self, data):
        x, y = data
        return x

OPTIONS = {
    "batchsize": [40],
    "timesteps": [TIMESTEPS],
    "optimizer": ["adam"],
    "loss": ['mae', 'mse'],
    "metrics": ['mae', 'mse'],
    # "layer1": [{"units": i*5} for i in range(1, 10)],
}